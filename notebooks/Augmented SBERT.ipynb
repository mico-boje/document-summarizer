{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, losses, util\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, BinaryClassificationEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "import csv\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import gzip\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "#You can specify any huggingface/transformers pre-trained model here, for example, bert-base-uncased, roberta-base, xlm-roberta-base\n",
    "#model_name = sys.argv[1] if len(sys.argv) > 1 else 'bert-base-uncased'\n",
    "model_name = \"roberta-base\"\n",
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "max_seq_length = 128\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "###### Read Datasets ######\n",
    "sts_dataset_path = 'datasets/stsbenchmark.tsv.gz'\n",
    "qqp_dataset_path = 'quora-IR-dataset'\n",
    "\n",
    "\n",
    "# Check if the STSb dataset exsist. If not, download and extract it\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)\n",
    "\n",
    "\n",
    "# Check if the QQP dataset exists. If not, download and extract\n",
    "if not os.path.exists(qqp_dataset_path):\n",
    "    logging.info(\"Dataset not found. Download\")\n",
    "    zip_save_path = 'quora-IR-dataset.zip'\n",
    "    util.http_get(url='https://sbert.net/datasets/quora-IR-dataset.zip', path=zip_save_path)\n",
    "    with ZipFile(zip_save_path, 'r') as zipIn:\n",
    "        zipIn.extractall(qqp_dataset_path)\n",
    "\n",
    "\n",
    "cross_encoder_path = 'output/cross-encoder/stsb_indomain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "bi_encoder_path = 'output/bi-encoder/qqp_cross_domain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:06:41 - Loading cross-encoder model: roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:06:47 - Use pytorch device: cuda\n",
      "2020-11-01 18:06:47 - Loading bi-encoder model: roberta-base\n",
      "2020-11-01 18:06:52 - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "###### Cross-encoder (simpletransformers) ######\n",
    "\n",
    "logging.info(\"Loading cross-encoder model: {}\".format(model_name))\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for cross-encoder model\n",
    "cross_encoder = CrossEncoder(model_name, num_labels=1)\n",
    "\n",
    "###### Bi-encoder (sentence-transformers) ######\n",
    "\n",
    "logging.info(\"Loading bi-encoder model: {}\".format(model_name))\n",
    "\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 18:06:52 - Step 1: Train cross-encoder: roberta-base with STSbenchmark (source dataset)\n",
      "2020-11-01 18:06:52 - Warmup-steps: 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07ec24bc82d4cd6884242ff5232121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523f38c48a714db5bb6c1fb4b4ade5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=719.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 18:08:21 - CECorrelationEvaluator: Evaluating the model on sts-dev dataset after epoch 0:\n",
      "2020-11-01 18:08:23 - Correlation:\tPearson: 0.9071\tSpearman: 0.9036\n",
      "2020-11-01 18:08:23 - Save model to output/cross-encoder/stsb_indomain_roberta-base-2020-11-01_18-06-41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Step 1: Train cross-encoder: {} with STSbenchmark (source dataset)\".format(model_name))\n",
    "\n",
    "gold_samples = []\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "\n",
    "        if row['split'] == 'dev':\n",
    "            dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "        elif row['split'] == 'test':\n",
    "            test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "        else:\n",
    "            #As we want to get symmetric scores, i.e. CrossEncoder(A,B) = CrossEncoder(B,A), we pass both combinations to the train set\n",
    "            gold_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "            gold_samples.append(InputExample(texts=[row['sentence2'], row['sentence1']], label=score))\n",
    "\n",
    "\n",
    "# We wrap gold_samples (which is a List[InputExample]) into a pytorch DataLoader\n",
    "train_dataloader = DataLoader(gold_samples, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# We add an evaluator, which evaluates the performance during training\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Train the cross-encoder model\n",
    "cross_encoder.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=cross_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 19:03:00 - Step 2: Label QQP (target dataset) with cross-encoder: roberta-base\n",
      "2020-11-01 19:03:04 - Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6736ef21e90d48a5ae63e3f8018e9752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=3240.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Step 2: Label QQP (target dataset) with cross-encoder: {}\".format(model_name))\n",
    "\n",
    "cross_encoder = CrossEncoder(cross_encoder_path)\n",
    "\n",
    "silver_data = []\n",
    "\n",
    "with open(os.path.join(qqp_dataset_path, \"classification/train_pairs.tsv\"), encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        if row['is_duplicate'] == '1':\n",
    "            silver_data.append([row['question1'], row['question2']])\n",
    "\n",
    "silver_scores1 = cross_encoder.predict(silver_data)\n",
    "\n",
    "# All model predictions should be between [0,1]\n",
    "assert all(0.0 <= score <= 1.0 for score in silver_scores1)\n",
    "\n",
    "binary_silver_scores1 = [1 if score >= 0.5 else 0 for score in silver_scores1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92399\n",
      "11264\n"
     ]
    }
   ],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "for i in binary_silver_scores1:\n",
    "    if i == 1:\n",
    "        count1 += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "print(count1)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "filename = r'/home/miboj/NLP/document-summarizer/data/processed/articles.json'\n",
    "file = open(filename, encoding='ascii', errors='ignore')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "json_content = ast.literal_eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_empty_string(input_string):\n",
    "    for e, i in enumerate(input_string):\n",
    "        try:\n",
    "            if i[-1] == ' ' and input_string[e+1][-1] == ' ':\n",
    "                input_string[e] = i.rstrip()\n",
    "        except IndexError:\n",
    "            print('Out of index')\n",
    "    joined_string = ''.join(input_string)\n",
    "    try:\n",
    "        for e, i in enumerate(joined_string):\n",
    "            if i == ' ' and joined_string[e+1] == ' ':\n",
    "                del i\n",
    "    except IndexError:\n",
    "            print()\n",
    "    sentences = nltk.sent_tokenize(joined_string)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_list = []\n",
    "for i in json_content:\n",
    "    for sen in i['content']:\n",
    "        for o in nltk.sent_tokenize(sen):\n",
    "            sen_list.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But the current serviceability state of this equipment, particularly those with the Indian Air Force (IAF) and the Navy, is less than 50 percent because of a lack of spares.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_list[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data = []\n",
    "count = 0\n",
    "for i in sen_list:\n",
    "    try:\n",
    "        silver_data.append([sen_list[count], sen_list[count+1]])\n",
    "    except IndexError:\n",
    "        break\n",
    "    count += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When it comes to leading at the highest levels of joint strategy and policy, and as someone who sets the standard for critical collaboration with our allies and partners, there is no one more qualified for the role of vice chief.',\n",
       " ' Allvin will succeed the current vice chief, Gen. Seve Wilson, who is expected to retire after 39 years in uniform.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silver_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d864dbc6594b428d8d9a1f3c63ca58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batches', max=2270.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "silver_scores = cross_encoder.predict(silver_data)\n",
    "\n",
    "# All model predictions should be between [0,1]\n",
    "assert all(0.0 <= score <= 1.0 for score in silver_scores)\n",
    "\n",
    "binary_silver_scores = [1 if score >= 0.5 else 0 for score in silver_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4412\n",
      "68201\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for i in binary_silver_scores:\n",
    "    if i == 1:\n",
    "        count += 1\n",
    "    else:\n",
    "        count2 += 1\n",
    "        \n",
    "print(count)\n",
    "print(count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 19:49:59 - Step 3: Train bi-encoder: roberta-base over labeled QQP (target dataset)\n",
      "2020-11-01 19:49:59 - Loading BERT labeled QQP dataset\n",
      "2020-11-01 19:49:59 - Read QQP dev dataset\n",
      "2020-11-01 19:50:00 - Warmup-steps: 454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cb2a98567e447189c19c99eb0874f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=10.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150ab0215645464486a42593b2702750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 19:59:02 - Binary Accuracy Evaluation of the model on  dataset after epoch 0:\n",
      "2020-11-01 19:59:53 - Accuracy with Cosine-Similarity:           77.64\t(Threshold: 0.8493)\n",
      "2020-11-01 19:59:53 - F1 with Cosine-Similarity:                 70.89\t(Threshold: 0.7801)\n",
      "2020-11-01 19:59:53 - Precision with Cosine-Similarity:          60.73\n",
      "2020-11-01 19:59:53 - Recall with Cosine-Similarity:             85.14\n",
      "2020-11-01 19:59:53 - Average Precision with Cosine-Similarity:  73.21\n",
      "\n",
      "2020-11-01 19:59:54 - Accuracy with Manhatten-Distance:           77.57\t(Threshold: 197.8090)\n",
      "2020-11-01 19:59:54 - F1 with Manhatten-Distance:                 70.81\t(Threshold: 233.6341)\n",
      "2020-11-01 19:59:54 - Precision with Manhatten-Distance:          61.94\n",
      "2020-11-01 19:59:54 - Recall with Manhatten-Distance:             82.64\n",
      "2020-11-01 19:59:54 - Average Precision with Manhatten-Distance:  73.02\n",
      "\n",
      "2020-11-01 19:59:54 - Accuracy with Euclidean-Distance:           77.60\t(Threshold: 9.0927)\n",
      "2020-11-01 19:59:54 - F1 with Euclidean-Distance:                 70.78\t(Threshold: 10.7493)\n",
      "2020-11-01 19:59:54 - Precision with Euclidean-Distance:          61.95\n",
      "2020-11-01 19:59:54 - Recall with Euclidean-Distance:             82.54\n",
      "2020-11-01 19:59:54 - Average Precision with Euclidean-Distance:  73.07\n",
      "\n",
      "2020-11-01 19:59:54 - Save model to output/bi-encoder/qqp_cross_domain_roberta-base-2020-11-01_18-06-41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f69801477ae4bfe82e6badcdf01e880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:08:42 - Binary Accuracy Evaluation of the model on  dataset after epoch 1:\n",
      "2020-11-01 20:09:33 - Accuracy with Cosine-Similarity:           77.62\t(Threshold: 0.8424)\n",
      "2020-11-01 20:09:33 - F1 with Cosine-Similarity:                 71.21\t(Threshold: 0.7595)\n",
      "2020-11-01 20:09:33 - Precision with Cosine-Similarity:          60.70\n",
      "2020-11-01 20:09:33 - Recall with Cosine-Similarity:             86.11\n",
      "2020-11-01 20:09:33 - Average Precision with Cosine-Similarity:  73.21\n",
      "\n",
      "2020-11-01 20:09:34 - Accuracy with Manhatten-Distance:           77.08\t(Threshold: 203.9983)\n",
      "2020-11-01 20:09:34 - F1 with Manhatten-Distance:                 70.08\t(Threshold: 233.7149)\n",
      "2020-11-01 20:09:34 - Precision with Manhatten-Distance:          61.75\n",
      "2020-11-01 20:09:34 - Recall with Manhatten-Distance:             80.99\n",
      "2020-11-01 20:09:34 - Average Precision with Manhatten-Distance:  72.12\n",
      "\n",
      "2020-11-01 20:09:34 - Accuracy with Euclidean-Distance:           77.11\t(Threshold: 9.1936)\n",
      "2020-11-01 20:09:34 - F1 with Euclidean-Distance:                 70.17\t(Threshold: 10.7719)\n",
      "2020-11-01 20:09:34 - Precision with Euclidean-Distance:          61.82\n",
      "2020-11-01 20:09:34 - Recall with Euclidean-Distance:             81.13\n",
      "2020-11-01 20:09:34 - Average Precision with Euclidean-Distance:  72.21\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b4837eb0b44d0891239a0d8abd1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:18:20 - Binary Accuracy Evaluation of the model on  dataset after epoch 2:\n",
      "2020-11-01 20:19:11 - Accuracy with Cosine-Similarity:           77.74\t(Threshold: 0.8379)\n",
      "2020-11-01 20:19:11 - F1 with Cosine-Similarity:                 70.99\t(Threshold: 0.7499)\n",
      "2020-11-01 20:19:11 - Precision with Cosine-Similarity:          61.07\n",
      "2020-11-01 20:19:11 - Recall with Cosine-Similarity:             84.76\n",
      "2020-11-01 20:19:11 - Average Precision with Cosine-Similarity:  71.62\n",
      "\n",
      "2020-11-01 20:19:11 - Accuracy with Manhatten-Distance:           77.05\t(Threshold: 191.3977)\n",
      "2020-11-01 20:19:11 - F1 with Manhatten-Distance:                 70.13\t(Threshold: 242.3848)\n",
      "2020-11-01 20:19:11 - Precision with Manhatten-Distance:          60.23\n",
      "2020-11-01 20:19:11 - Recall with Manhatten-Distance:             83.92\n",
      "2020-11-01 20:19:11 - Average Precision with Manhatten-Distance:  70.66\n",
      "\n",
      "2020-11-01 20:19:12 - Accuracy with Euclidean-Distance:           77.09\t(Threshold: 8.9445)\n",
      "2020-11-01 20:19:12 - F1 with Euclidean-Distance:                 70.15\t(Threshold: 11.0971)\n",
      "2020-11-01 20:19:12 - Precision with Euclidean-Distance:          60.52\n",
      "2020-11-01 20:19:12 - Recall with Euclidean-Distance:             83.42\n",
      "2020-11-01 20:19:12 - Average Precision with Euclidean-Distance:  70.73\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b09c2c8ca44e50a57ff7ba240e2227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:27:55 - Binary Accuracy Evaluation of the model on  dataset after epoch 3:\n",
      "2020-11-01 20:28:49 - Accuracy with Cosine-Similarity:           78.62\t(Threshold: 0.8367)\n",
      "2020-11-01 20:28:49 - F1 with Cosine-Similarity:                 72.15\t(Threshold: 0.7766)\n",
      "2020-11-01 20:28:49 - Precision with Cosine-Similarity:          63.66\n",
      "2020-11-01 20:28:49 - Recall with Cosine-Similarity:             83.26\n",
      "2020-11-01 20:28:49 - Average Precision with Cosine-Similarity:  74.64\n",
      "\n",
      "2020-11-01 20:28:49 - Accuracy with Manhatten-Distance:           78.30\t(Threshold: 219.6533)\n",
      "2020-11-01 20:28:49 - F1 with Manhatten-Distance:                 71.58\t(Threshold: 257.6602)\n",
      "2020-11-01 20:28:49 - Precision with Manhatten-Distance:          62.60\n",
      "2020-11-01 20:28:49 - Recall with Manhatten-Distance:             83.56\n",
      "2020-11-01 20:28:49 - Average Precision with Manhatten-Distance:  74.10\n",
      "\n",
      "2020-11-01 20:28:50 - Accuracy with Euclidean-Distance:           78.30\t(Threshold: 10.1187)\n",
      "2020-11-01 20:28:50 - F1 with Euclidean-Distance:                 71.58\t(Threshold: 11.7946)\n",
      "2020-11-01 20:28:50 - Precision with Euclidean-Distance:          62.73\n",
      "2020-11-01 20:28:50 - Recall with Euclidean-Distance:             83.34\n",
      "2020-11-01 20:28:50 - Average Precision with Euclidean-Distance:  74.15\n",
      "\n",
      "2020-11-01 20:28:50 - Save model to output/bi-encoder/qqp_cross_domain_roberta-base-2020-11-01_18-06-41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99375cff81f4583a0a0e066447e7969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:37:36 - Binary Accuracy Evaluation of the model on  dataset after epoch 4:\n",
      "2020-11-01 20:38:27 - Accuracy with Cosine-Similarity:           77.85\t(Threshold: 0.8187)\n",
      "2020-11-01 20:38:27 - F1 with Cosine-Similarity:                 71.17\t(Threshold: 0.7658)\n",
      "2020-11-01 20:38:27 - Precision with Cosine-Similarity:          61.85\n",
      "2020-11-01 20:38:27 - Recall with Cosine-Similarity:             83.79\n",
      "2020-11-01 20:38:27 - Average Precision with Cosine-Similarity:  72.47\n",
      "\n",
      "2020-11-01 20:38:27 - Accuracy with Manhatten-Distance:           77.38\t(Threshold: 205.4686)\n",
      "2020-11-01 20:38:27 - F1 with Manhatten-Distance:                 70.35\t(Threshold: 229.6387)\n",
      "2020-11-01 20:38:27 - Precision with Manhatten-Distance:          62.67\n",
      "2020-11-01 20:38:27 - Recall with Manhatten-Distance:             80.19\n",
      "2020-11-01 20:38:27 - Average Precision with Manhatten-Distance:  71.77\n",
      "\n",
      "2020-11-01 20:38:28 - Accuracy with Euclidean-Distance:           77.40\t(Threshold: 9.4526)\n",
      "2020-11-01 20:38:28 - F1 with Euclidean-Distance:                 70.46\t(Threshold: 10.6828)\n",
      "2020-11-01 20:38:28 - Precision with Euclidean-Distance:          62.35\n",
      "2020-11-01 20:38:28 - Recall with Euclidean-Distance:             80.98\n",
      "2020-11-01 20:38:28 - Average Precision with Euclidean-Distance:  71.81\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca068cebeb474d418d4e062550ffa1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:47:12 - Binary Accuracy Evaluation of the model on  dataset after epoch 5:\n",
      "2020-11-01 20:48:04 - Accuracy with Cosine-Similarity:           78.37\t(Threshold: 0.8401)\n",
      "2020-11-01 20:48:04 - F1 with Cosine-Similarity:                 71.30\t(Threshold: 0.7566)\n",
      "2020-11-01 20:48:04 - Precision with Cosine-Similarity:          61.40\n",
      "2020-11-01 20:48:04 - Recall with Cosine-Similarity:             85.01\n",
      "2020-11-01 20:48:04 - Average Precision with Cosine-Similarity:  73.30\n",
      "\n",
      "2020-11-01 20:48:05 - Accuracy with Manhatten-Distance:           77.99\t(Threshold: 194.8791)\n",
      "2020-11-01 20:48:05 - F1 with Manhatten-Distance:                 70.76\t(Threshold: 239.9119)\n",
      "2020-11-01 20:48:05 - Precision with Manhatten-Distance:          61.75\n",
      "2020-11-01 20:48:05 - Recall with Manhatten-Distance:             82.85\n",
      "2020-11-01 20:48:05 - Average Precision with Manhatten-Distance:  72.79\n",
      "\n",
      "2020-11-01 20:48:05 - Accuracy with Euclidean-Distance:           78.06\t(Threshold: 9.0642)\n",
      "2020-11-01 20:48:05 - F1 with Euclidean-Distance:                 70.85\t(Threshold: 10.9936)\n",
      "2020-11-01 20:48:05 - Precision with Euclidean-Distance:          62.04\n",
      "2020-11-01 20:48:05 - Recall with Euclidean-Distance:             82.59\n",
      "2020-11-01 20:48:05 - Average Precision with Euclidean-Distance:  72.85\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689f1bc1cabd4b87ba6a9cc33ff58c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 20:56:51 - Binary Accuracy Evaluation of the model on  dataset after epoch 6:\n",
      "2020-11-01 20:57:42 - Accuracy with Cosine-Similarity:           78.50\t(Threshold: 0.8432)\n",
      "2020-11-01 20:57:42 - F1 with Cosine-Similarity:                 71.97\t(Threshold: 0.7622)\n",
      "2020-11-01 20:57:42 - Precision with Cosine-Similarity:          62.23\n",
      "2020-11-01 20:57:42 - Recall with Cosine-Similarity:             85.33\n",
      "2020-11-01 20:57:42 - Average Precision with Cosine-Similarity:  73.87\n",
      "\n",
      "2020-11-01 20:57:43 - Accuracy with Manhatten-Distance:           78.17\t(Threshold: 207.6480)\n",
      "2020-11-01 20:57:43 - F1 with Manhatten-Distance:                 71.30\t(Threshold: 246.2399)\n",
      "2020-11-01 20:57:43 - Precision with Manhatten-Distance:          62.63\n",
      "2020-11-01 20:57:43 - Recall with Manhatten-Distance:             82.75\n",
      "2020-11-01 20:57:43 - Average Precision with Manhatten-Distance:  73.38\n",
      "\n",
      "2020-11-01 20:57:43 - Accuracy with Euclidean-Distance:           78.23\t(Threshold: 9.5726)\n",
      "2020-11-01 20:57:43 - F1 with Euclidean-Distance:                 71.34\t(Threshold: 11.2726)\n",
      "2020-11-01 20:57:43 - Precision with Euclidean-Distance:          62.89\n",
      "2020-11-01 20:57:43 - Recall with Euclidean-Distance:             82.40\n",
      "2020-11-01 20:57:43 - Average Precision with Euclidean-Distance:  73.45\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d77e50dccf458faea4e1f62dce4d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 21:06:29 - Binary Accuracy Evaluation of the model on  dataset after epoch 7:\n",
      "2020-11-01 21:07:21 - Accuracy with Cosine-Similarity:           78.51\t(Threshold: 0.8462)\n",
      "2020-11-01 21:07:21 - F1 with Cosine-Similarity:                 71.99\t(Threshold: 0.7699)\n",
      "2020-11-01 21:07:21 - Precision with Cosine-Similarity:          63.19\n",
      "2020-11-01 21:07:21 - Recall with Cosine-Similarity:             83.62\n",
      "2020-11-01 21:07:21 - Average Precision with Cosine-Similarity:  73.95\n",
      "\n",
      "2020-11-01 21:07:21 - Accuracy with Manhatten-Distance:           78.10\t(Threshold: 207.1911)\n",
      "2020-11-01 21:07:21 - F1 with Manhatten-Distance:                 71.34\t(Threshold: 239.8456)\n",
      "2020-11-01 21:07:21 - Precision with Manhatten-Distance:          63.36\n",
      "2020-11-01 21:07:21 - Recall with Manhatten-Distance:             81.61\n",
      "2020-11-01 21:07:21 - Average Precision with Manhatten-Distance:  73.31\n",
      "\n",
      "2020-11-01 21:07:21 - Accuracy with Euclidean-Distance:           78.11\t(Threshold: 9.5683)\n",
      "2020-11-01 21:07:21 - F1 with Euclidean-Distance:                 71.37\t(Threshold: 11.0751)\n",
      "2020-11-01 21:07:21 - Precision with Euclidean-Distance:          63.32\n",
      "2020-11-01 21:07:21 - Recall with Euclidean-Distance:             81.77\n",
      "2020-11-01 21:07:21 - Average Precision with Euclidean-Distance:  73.39\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e938be10df94242ae7ead97b8cea90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 21:16:08 - Binary Accuracy Evaluation of the model on  dataset after epoch 8:\n",
      "2020-11-01 21:17:02 - Accuracy with Cosine-Similarity:           78.63\t(Threshold: 0.8316)\n",
      "2020-11-01 21:17:02 - F1 with Cosine-Similarity:                 71.96\t(Threshold: 0.7690)\n",
      "2020-11-01 21:17:02 - Precision with Cosine-Similarity:          63.35\n",
      "2020-11-01 21:17:02 - Recall with Cosine-Similarity:             83.29\n",
      "2020-11-01 21:17:02 - Average Precision with Cosine-Similarity:  73.78\n",
      "\n",
      "2020-11-01 21:17:02 - Accuracy with Manhatten-Distance:           78.16\t(Threshold: 212.4594)\n",
      "2020-11-01 21:17:02 - F1 with Manhatten-Distance:                 71.42\t(Threshold: 246.7106)\n",
      "2020-11-01 21:17:02 - Precision with Manhatten-Distance:          63.18\n",
      "2020-11-01 21:17:02 - Recall with Manhatten-Distance:             82.12\n",
      "2020-11-01 21:17:02 - Average Precision with Manhatten-Distance:  73.25\n",
      "\n",
      "2020-11-01 21:17:03 - Accuracy with Euclidean-Distance:           78.22\t(Threshold: 9.7475)\n",
      "2020-11-01 21:17:03 - F1 with Euclidean-Distance:                 71.51\t(Threshold: 11.2044)\n",
      "2020-11-01 21:17:03 - Precision with Euclidean-Distance:          63.81\n",
      "2020-11-01 21:17:03 - Recall with Euclidean-Distance:             81.32\n",
      "2020-11-01 21:17:03 - Average Precision with Euclidean-Distance:  73.34\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcba6aa751140cd9e1c1e1f1f6ed35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=4539.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-01 21:25:47 - Binary Accuracy Evaluation of the model on  dataset after epoch 9:\n",
      "2020-11-01 21:26:39 - Accuracy with Cosine-Similarity:           78.64\t(Threshold: 0.8312)\n",
      "2020-11-01 21:26:39 - F1 with Cosine-Similarity:                 71.91\t(Threshold: 0.7704)\n",
      "2020-11-01 21:26:39 - Precision with Cosine-Similarity:          63.42\n",
      "2020-11-01 21:26:39 - Recall with Cosine-Similarity:             83.02\n",
      "2020-11-01 21:26:39 - Average Precision with Cosine-Similarity:  73.87\n",
      "\n",
      "2020-11-01 21:26:39 - Accuracy with Manhatten-Distance:           78.27\t(Threshold: 214.8118)\n",
      "2020-11-01 21:26:39 - F1 with Manhatten-Distance:                 71.44\t(Threshold: 242.2879)\n",
      "2020-11-01 21:26:39 - Precision with Manhatten-Distance:          64.37\n",
      "2020-11-01 21:26:39 - Recall with Manhatten-Distance:             80.25\n",
      "2020-11-01 21:26:39 - Average Precision with Manhatten-Distance:  73.37\n",
      "\n",
      "2020-11-01 21:26:39 - Accuracy with Euclidean-Distance:           78.33\t(Threshold: 9.8158)\n",
      "2020-11-01 21:26:39 - F1 with Euclidean-Distance:                 71.54\t(Threshold: 11.3332)\n",
      "2020-11-01 21:26:39 - Precision with Euclidean-Distance:          63.79\n",
      "2020-11-01 21:26:39 - Recall with Euclidean-Distance:             81.43\n",
      "2020-11-01 21:26:39 - Average Precision with Euclidean-Distance:  73.45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Step 3: Train bi-encoder: {} over labeled QQP (target dataset)\".format(model_name))\n",
    "\n",
    "# Convert the dataset to a DataLoader ready for training\n",
    "logging.info(\"Loading BERT labeled QQP dataset\")\n",
    "qqp_train_data = list(InputExample(texts=[data[0], data[1]], label=score) for (data, score) in zip(silver_data, binary_silver_scores))\n",
    "\n",
    "train_dataset = SentencesDataset(qqp_train_data, bi_encoder)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(bi_encoder)\n",
    "\n",
    "###### Classification ######\n",
    "# Given (quesiton1, question2), is this a duplicate or not?\n",
    "# The evaluator will compute the embeddings for both questions and then compute\n",
    "# a cosine similarity. If the similarity is above a threshold, we have a duplicate.\n",
    "logging.info(\"Read QQP dev dataset\")\n",
    "\n",
    "dev_sentences1 = []\n",
    "dev_sentences2 = []\n",
    "dev_labels = []\n",
    "\n",
    "with open(os.path.join(qqp_dataset_path, \"classification/dev_pairs.tsv\"), encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        dev_sentences1.append(row['question1'])\n",
    "        dev_sentences2.append(row['question2'])\n",
    "        dev_labels.append(int(row['is_duplicate']))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(dev_sentences1, dev_sentences2, dev_labels)\n",
    "\n",
    "# Configure the training.\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / batch_size * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Train the bi-encoder model\n",
    "bi_encoder.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=evaluator,\n",
    "          epochs=10,\n",
    "          #evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=bi_encoder_path,\n",
    "          output_path_ignore_not_empty=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-01 16:18:00 - Load pretrained SentenceTransformer: output/bi-encoder/qqp_cross_domain_roberta-base-2020-11-01_15-00-31\n",
      "2020-11-01 16:18:00 - Load SentenceTransformer from folder: output/bi-encoder/qqp_cross_domain_roberta-base-2020-11-01_15-00-31\n",
      "2020-11-01 16:18:03 - Use pytorch device: cuda\n",
      "2020-11-01 16:18:03 - Read QQP test dataset\n",
      "2020-11-01 16:18:03 - Binary Accuracy Evaluation of the model on  dataset:\n",
      "2020-11-01 16:19:55 - Accuracy with Cosine-Similarity:           76.97\t(Threshold: 0.7849)\n",
      "2020-11-01 16:19:55 - F1 with Cosine-Similarity:                 74.69\t(Threshold: 0.7238)\n",
      "2020-11-01 16:19:55 - Precision with Cosine-Similarity:          64.50\n",
      "2020-11-01 16:19:55 - Recall with Cosine-Similarity:             88.71\n",
      "2020-11-01 16:19:55 - Average Precision with Cosine-Similarity:  75.68\n",
      "\n",
      "2020-11-01 16:19:55 - Accuracy with Manhatten-Distance:           76.45\t(Threshold: 246.6084)\n",
      "2020-11-01 16:19:55 - F1 with Manhatten-Distance:                 74.00\t(Threshold: 278.2165)\n",
      "2020-11-01 16:19:55 - Precision with Manhatten-Distance:          64.13\n",
      "2020-11-01 16:19:55 - Recall with Manhatten-Distance:             87.45\n",
      "2020-11-01 16:19:55 - Average Precision with Manhatten-Distance:  75.08\n",
      "\n",
      "2020-11-01 16:19:56 - Accuracy with Euclidean-Distance:           76.46\t(Threshold: 11.2660)\n",
      "2020-11-01 16:19:56 - F1 with Euclidean-Distance:                 74.06\t(Threshold: 12.8831)\n",
      "2020-11-01 16:19:56 - Precision with Euclidean-Distance:          64.05\n",
      "2020-11-01 16:19:56 - Recall with Euclidean-Distance:             87.79\n",
      "2020-11-01 16:19:56 - Average Precision with Euclidean-Distance:  75.11\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7567855674036059"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder = SentenceTransformer(bi_encoder_path)\n",
    "\n",
    "logging.info(\"Read QQP test dataset\")\n",
    "test_sentences1 = []\n",
    "test_sentences2 = []\n",
    "test_labels = []\n",
    "\n",
    "with open(os.path.join(qqp_dataset_path, \"classification/test_pairs.tsv\"), encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        test_sentences1.append(row['question1'])\n",
    "        test_sentences2.append(row['question2'])\n",
    "        test_labels.append(int(row['is_duplicate']))\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(test_sentences1, test_sentences2, test_labels)\n",
    "bi_encoder.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-62300c4ca054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentences2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(1,1500):\n",
    "    if test_labels[i] != 0 and test_labels[i] != 1:\n",
    "        print(test_sentences1[i])\n",
    "        print(test_sentences2[i])\n",
    "        print(test_labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
