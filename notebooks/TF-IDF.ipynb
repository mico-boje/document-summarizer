{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/miboj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/miboj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import ast\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'/home/miboj/NLP/document-summarizer/data/processed/articles.json'\n",
    "file = open(filename, encoding='ascii', errors='ignore')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "d = ast.literal_eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "filename = r'/home/miboj/NLP/document-summarizer/data/processed/articles.json'\n",
    "file = open(filename, encoding='ascii', errors='ignore')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "json_content = ast.literal_eval(text)\n",
    "samples = json_content[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_list = []\n",
    "for i in d:\n",
    "    for sen in i['content']:\n",
    "        tokens_list.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 32.63631463050842 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "sentences = []\n",
    "word_count = 0\n",
    "stpwrds = stopwords.words('english') + list(string.punctuation) + ['—', '“', '”', \"'\", \"’\"]\n",
    "for e, i in enumerate(tokens_list):\n",
    "    words = []\n",
    "    a = nltk.word_tokenize(i)\n",
    "    for word in a:\n",
    "        if word not in stpwrds:\n",
    "            words.append(word)\n",
    "            word_count += 1\n",
    "    sentences.append(words)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Lt. Gen. David Allvin was confirmed by the Senate to be the Air Forces next vice chief of staff in a late-night vote Wednesday.\n"
     ]
    }
   ],
   "source": [
    "for text in tokens_list:\n",
    "    print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation_marks(text):\n",
    "    punctuation_marks = dict((ord(punctuation_mark), None) for punctuation_mark in string.punctuation)\n",
    "    return text.translate(punctuation_marks)\n",
    "\n",
    "def remove_punctuation_marks2(sentences):\n",
    "    punctutaion_marks = None\n",
    "    for text in sentences:\n",
    "        if punctutaion_marks == None:\n",
    "             punctuation_marks = dict((ord(punctuation_mark), None) for punctuation_mark in string.punctuation)\n",
    "        else:\n",
    "            punctuation_marks += dict((ord(punctuation_mark), None) for punctuation_mark in string.punctuation)\n",
    "    return text.translate(punctuation_marks)\n",
    "\n",
    "def get_tokens(sentences) :\n",
    "    normalized_tokens = nltk.word_tokenize(remove_punctuation_marks(text.lower()))\n",
    "    # Lemmatized\n",
    "    #return [nltk.stem.WordNetLemmatizer().lemmatize(normalized_token) for normalized_token in normalized_tokens]\n",
    "    # Stemmed\n",
    "    return [nltk.stem.PorterStemmer().stem(normalized_token) for normalized_token in normalized_tokens]\n",
    "\n",
    "def calculate_sentence_scores(sentence_tokens, tfIdf):\n",
    "    sentence_scores = {}\n",
    "    for sent in sentence_tokens:\n",
    "        #for word in nltk.word_tokenize(sent.lower()):\n",
    "        for word in get_tokens(sent):    \n",
    "            if word in tfIdf.keys():\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = tfIdf[word]/len(sent)\n",
    "                else:\n",
    "                    sentence_scores[sent] += tfIdf[word]/len(sent)                    \n",
    "    return sentence_scores\n",
    "\n",
    "def get_summary(summary_max_length, sentence_scores):\n",
    "    summary_sentences = heapq.nlargest(summary_max_length, sentence_scores, key=sentence_scores.get)\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miboj/miniconda3/envs/NLP-env/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['air', 'allvin', 'chief', 'confirm', 'david', 'forc', 'gen', 'latenight', 'lt', 'next', 'senat', 'staff', 'vice', 'vote', 'wa', 'wednesday'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "stpwrds = stopwords.words('english') + list(string.punctuation) + ['—', '“', '”', \"'\", \"’\"]\n",
    "vectorizer = TfidfVectorizer(tokenizer = get_tokens, stop_words = stpwrds)\n",
    "tfIdf = vectorizer.fit_transform(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>air</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allvin</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chief</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirm</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>david</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forc</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latenight</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>next</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senat</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wednesday</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TF-IDF\n",
       "air          0.25\n",
       "allvin       0.25\n",
       "chief        0.25\n",
       "confirm      0.25\n",
       "david        0.25\n",
       "forc         0.25\n",
       "gen          0.25\n",
       "latenight    0.25\n",
       "lt           0.25\n",
       "next         0.25\n",
       "senat        0.25\n",
       "staff        0.25\n",
       "vice         0.25\n",
       "vote         0.25\n",
       "wa           0.25\n",
       "wednesday    0.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lt', 'gen', 'david', 'allvin', 'wa', 'confirm', 'by', 'the', 'senat', 'to', 'be', 'the', 'air', 'forc', 'next', 'vice', 'chief', 'of', 'staff', 'in', 'a', 'latenight', 'vote', 'wednesday']\n",
      "playing\n",
      "play\n",
      "play\n",
      "play\n"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "a = get_tokens('playing')\n",
    "b = nltk.stem.WordNetLemmatizer().lemmatize('playing')\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "print(a)\n",
    "print(b)\n",
    "porter = nltk.stem.PorterStemmer()\n",
    "lancaster = nltk.stem.LancasterStemmer()\n",
    "print(porter.stem('playing'))\n",
    "print(lancaster.stem('playing'))\n",
    "print(wnl.lemmatize('playing', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_string(input_string):\n",
    "    for e, i in enumerate(input_string):\n",
    "        try:\n",
    "            if i[-1] == ' ' and input_string[e+1][-1] == ' ':\n",
    "                input_string[e] = i.rstrip()\n",
    "        except IndexError:\n",
    "            continue\n",
    "    joined_string = ''.join(input_string)\n",
    "    for e, i in enumerate(joined_string):\n",
    "        if i == ' ' and joined_string[e+1] == ' ':\n",
    "            del i\n",
    "    sentences = nltk.sent_tokenize(joined_string)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document to summarized\n",
    "#document = nltk.sent_tokenize(stories[1]['story'])\n",
    "raw_string = [\" ROME — Defying reports that their planned partnership is \", \"doomed to fail\", \", France’s Naval Group and \", \"Italy’s Fincantieri\", \" have announced a joint venture to build and export naval vessels. \", \" The two \", \"state-controlled shipyards\", \" said they were forming a 50-50 joint venture after months of talks to integrate their activities. The move comes as Europe’s fractured shipbuilding industry faces stiffer global competition. \", \" The firms said in a statement that the deal would allow them to “jointly prepare winning offers for binational programs and export market,” as well as create joint supply chains, research and testing. \", \" Naval Group and Fincantieri first announced talks on cooperation last year after the latter negotiated a controlling share in French shipyard STX. But the deal was reportedly losing momentum due to resistance from French industry and a political row between France and Italy over migrants. \", \" The new deal falls short of the 10 percent share swap predicted by French Economy and Finance Minister Bruno Le Maire earlier this year, and far short of the total integration envisaged by Fincantieri CEO Giuseppe Bono. \", \" The statement called the joint venture the “first steps” toward the creation of an alliance that would create “a more efficient and competitive European shipbuilding industry.”\", \" Naval Group CEO Hervé Guillou, speaking at the Euronaval trade expo in Paris on Oct. 24, said the alliance is based on “two countries sharing a veritable naval ambition.”\", \" The joint venture is necessary because the “context of the global market has changed drastically,” he added, specifically mentioning new market entrants Russia, China, Singapore, Ukraine, India and Turkey.\", \"Sign up for the Early Bird Brief, the defense industry's most comprehensive news and information, straight to your inbox.\", \"By giving us your email, you are opting in to the Early Bird Brief.\", \" When asked about an initial product to be tackled under the alliance, Guillou acknowledged: “The answer is simple: there is nothing yet.”\", \" However, the firms said they are working toward a deal to build four logistics support ships for the French Navy, which will be based on an Italian design. \", \"Competition flares up for the follow-on portion of a deal previously won by the French shipbuilder.\", \" The firms also plan to jointly bid next year on work for midlife upgrades for Horizon frigates, which were built by France and Italy and are in service with both navies. The work would include providing a common combat management system. \", \" The statement was cautious about future acceleration toward integration. “A Government-to-Government Agreement would be needed to ensure the protection of sovereign assets, a fluid collaboration between the French and Italian teams and encourage further coherence of the National assistance programs, which provide a framework and support export sales,” the statement said.\", \" But the firms were optimistic the deal would be “a great opportunity for both groups and their eco-systems, by enhancing their ability to better serve the Italian and French navies, to capture new export contracts, to increase research funding and, ultimately, improve the competitiveness of both French and Italian naval sectors.”\", \" \", \"Sebastian Sprenger\", \" in Paris contributed to this report.\"]\n",
    "document = remove_empty_string(raw_string)\n",
    "\n",
    "#document = stories[1]['story']\n",
    "\n",
    "tfIdf_dict = df.to_dict()\n",
    "def get_sentence_scores(document, tfIdf_dict):\n",
    "    sentence_scores = calculate_sentence_scores(document, tfIdf_dict['TF-IDF'])\n",
    "    return sentence_scores\n",
    "#summary = get_summary(3, sentence_scores)\n",
    "#print(summary)\n",
    "#print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n"
     ]
    }
   ],
   "source": [
    "summary_samples = []\n",
    "summary_len_list = []\n",
    "for i in samples:\n",
    "    sentences = remove_empty_string(i['content'])\n",
    "    scores = get_sentence_scores(sentences, tfIdf_dict)\n",
    "    summary_len = int(len(sentences)*0.3) \n",
    "    summary = get_summary(summary_len, scores)\n",
    "    summary_samples.append(summary)\n",
    "    summary_len_list.append(summary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n",
      "Out of index\n"
     ]
    }
   ],
   "source": [
    "sorted_summaries = []\n",
    "for e, i in enumerate(summary_samples):\n",
    "    a = nltk.sent_tokenize(i)\n",
    "    o = samples[e]['content']\n",
    "    b = remove_empty_string(o)\n",
    "    #print(a)\n",
    "    #print(b)\n",
    "    res = [sort for x in b for sort in a if sort == x]\n",
    "    sorted_summaries.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      "len original:  17\n",
      "Summary len:  5\n",
      "Allvins nomination to become vice chief and receive his fourth star was approved unanimously. In a Thursday release, Chief of Staff Gen. Charles CQ Brown applauded Allvins confirmation. Wilson has served in his role since July 2016 and is the longest-serving vice chief in Air Force history. His past commands include the 97th Air Mobility Wing at Altus Air Force Base in Oklahoma from 2007 to 2009. He has traveled to the Middle East to cover Air Force operations against the Islamic State. \n",
      "1 : \n",
      "len original:  18\n",
      "Summary len:  5\n",
      "The type will replace the older NAMC YS-11EB (right) in the role. The aircraft made its maiden flight in early 2018, though the variant had been in development since at least 2015. Japan is also seeking to recapitalize its standoff jamming capability. The EC-1 is based on the older Kawasaki C-1 that Japan is slowly replacing with the C-2. Fiscal 2019 received no funding for the effort. \n",
      "2 : \n",
      "len original:  14\n",
      "Summary len:  4\n",
      "The company has completed 5G system design across the installations and expects to complete delivery of the services by the end of 2021. He previously worked as a congressional reporting fellow for the Texas Tribune and Washington intern for the Durango Herald. Andrew is a graduate of American University. \n",
      "3 : \n",
      "len original:  10\n",
      "Summary len:  3\n",
      "The package covers the procurement of 13 Recovery of Airbase Denied by Ordnance (RADBO) vehicles, as well as three spares. The service awarded Parsons the sole-source contract on Sept. 23. Work will be performed in Huntsville, Ala., with a completion date of Sept. 2023. \n",
      "4 : \n",
      "len original:  15\n",
      "Summary len:  4\n",
      "ROBOpilots name belies the simplicity of the program. Importantly, ROBOpilot requires no permanent modifications. All operators need to do is remove the pilots' seats and replace them with ROBOpilot. On Sept. 24, the system returned to the skies for a 2.2 hour test flight over Utah. \n",
      "5 : \n",
      "len original:  39\n",
      "Summary len:  11\n",
      "CORRECTION - Blackwing is a reconnaissance system. The dash speed of the Switchblade 600 is 115 mph. The new version can fly for 40 minutes with a range of more than 40 kilometers. From [artificial intelligence] to autonomy, were not stopping there. He added there would be a fly-off in January followed by a downselect to a single supplier. Most of that testing was ground-launched against both fixed and moving targets. Then the 600 will progress into both maritime and aerial environments, Hanning said. Initial air-launch testing will begin at the start of next year, Hush said. I will keep you updated in the future.Jen Judson is the land warfare reporter for Defense News. She has covered defense in the Washington area for nearly a decade. She was previously a reporter at Politico and Inside Defense. \n",
      "6 : \n",
      "len original:  29\n",
      "Summary len:  8\n",
      "We think it may be a poor electrical connection that needs to be re-seated. We are currently evaluating a fix. Resolving this has caused a minor delay to delivery of this single airplane. So how do we fix this? The KC 46 has been an extremely problematical program. One issue is frankly the technical solution. Seven KC-46s have gone to Pease ANGB. This story is developing. \n",
      "7 : \n",
      "len original:  17\n",
      "Summary len:  5\n",
      "The MoD said the first production version of the drone flew in California on Sept. 25. Three ground control stations and other associated support equipment were also included in the deal. A commitment for the additional drones could come in April next year. Protector is the British version of General Atomics latest Predator variant, the MQ-9B Sky Guardian. Following completion of the work the drone will be delivered to the MoD in the summer of 2021. \n",
      "8 : \n",
      "len original:  16\n",
      "Summary len:  4\n",
      "The two packages were posted on the Defense Security Cooperation Agencys website Wednesday. The DSCA has previously done so with F-35 requests from Belgium and Canada. The five Patriot batteries come with an estimated $2.2 billion price tag. All vendors must meet a deadline of Nov. 18 to deliver final proposals. \n",
      "9 : \n",
      "len original:  17\n",
      "Summary len:  5\n",
      "There was 49.9 percent, or 1,597,030 votes, against. Amherd stressed that the aircraft budget is to be seen as a ceiling. All vendors must meet a deadline of Nov. 18 to deliver final proposals. Previously he served as managing editor for Defense News. He is based in Cologne, Germany. \n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import sys\n",
    "\n",
    "for e, i in enumerate(sorted_summaries):\n",
    "    print(e, \": \")\n",
    "    print(\"len original: \", len(remove_empty_string(samples[e]['content'])))\n",
    "    print(\"Summary len: \", summary_len_list[e])\n",
    "    summary = \"\"\n",
    "    for sen in i:\n",
    "        summary += sen\n",
    "        summary += \" \"\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
